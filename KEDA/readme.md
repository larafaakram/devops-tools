KEDA (**Kubernetes Event-Driven Autoscaling**) est un composant open-source qui permet de faire du **scaling automatique** des workloads Kubernetes en fonction d'Ã©vÃ©nements externes. Il Ã©tend les capacitÃ©s du **Horizontal Pod Autoscaler (HPA)** en permettant de rÃ©agir Ã  des mÃ©triques autres que celles de base (CPU/RAM).

### ğŸ”¹ **FonctionnalitÃ©s principales** :
1. **Scaling basÃ© sur des Ã©vÃ©nements** : KEDA peut ajuster dynamiquement le nombre de pods en fonction de sources dâ€™Ã©vÃ©nements comme les files de messages, les bases de donnÃ©es, ou les mÃ©triques cloud.
2. **Mode "Scale-to-Zero"** : Contrairement Ã  lâ€™HPA qui garde toujours au moins un pod actif, KEDA peut rÃ©duire les pods Ã  **zÃ©ro** lorsquâ€™aucune charge nâ€™est prÃ©sente.
3. **Plus de 50 scalers intÃ©grÃ©s** : Supporte des services comme AWS SQS, Azure Queue Storage, Kafka, Prometheus, RabbitMQ, etc.
4. **CompatibilitÃ© avec Kubernetes HPA** : KEDA agit comme un adaptateur et peut fonctionner avec lâ€™HPA natif.

### ğŸ”¹ **Cas d'usage** :
- **Traitement d'Ã©vÃ©nements asynchrones** (ex. : jobs batch, files de messages)
- **Ã‰conomie de ressources** avec le scale-to-zero
- **Autoscaling avancÃ©** sur des mÃ©triques personnalisÃ©es

ğŸ‘‰ **Exemple d'architecture avec KEDA** :  
Une application qui Ã©coute une file SQS et dÃ©marre automatiquement des pods lorsquâ€™un certain nombre de messages est dÃ©tectÃ©.
